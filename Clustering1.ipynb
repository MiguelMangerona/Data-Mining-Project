{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import math \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import sys\n",
    "sys.path.append('../Functions')\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'DM2425_ABCDEats_DATASET.csv'\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customer_id customer_region  customer_age  DOW_0\n",
      "0  1b8f824d5e            2360          18.0      1\n",
      "1  5d272b9dcb            8670          17.0      1\n",
      "2  f6d1b2ba63            4660          38.0      1\n",
      "3  180c632ed8            4660           NaN      0\n",
      "4  4eb37a6705            4660          20.0      0\n",
      "  customer_id customer_region  customer_age  DOW_1\n",
      "0  1b8f824d5e            2360          18.0      0\n",
      "1  5d272b9dcb            8670          17.0      0\n",
      "2  f6d1b2ba63            4660          38.0      0\n",
      "3  180c632ed8            4660           NaN      1\n",
      "4  4eb37a6705            4660          20.0      1\n",
      "  customer_id customer_region  customer_age  DOW_2\n",
      "0  1b8f824d5e            2360          18.0      0\n",
      "1  5d272b9dcb            8670          17.0      0\n",
      "2  f6d1b2ba63            4660          38.0      0\n",
      "3  180c632ed8            4660           NaN      0\n",
      "4  4eb37a6705            4660          20.0      0\n",
      "  customer_id customer_region  customer_age  DOW_3\n",
      "0  1b8f824d5e            2360          18.0      0\n",
      "1  5d272b9dcb            8670          17.0      0\n",
      "2  f6d1b2ba63            4660          38.0      0\n",
      "3  180c632ed8            4660           NaN      0\n",
      "4  4eb37a6705            4660          20.0      0\n",
      "  customer_id customer_region  customer_age  DOW_4\n",
      "0  1b8f824d5e            2360          18.0      0\n",
      "1  5d272b9dcb            8670          17.0      0\n",
      "2  f6d1b2ba63            4660          38.0      0\n",
      "3  180c632ed8            4660           NaN      0\n",
      "4  4eb37a6705            4660          20.0      0\n",
      "  customer_id customer_region  customer_age  DOW_5\n",
      "0  1b8f824d5e            2360          18.0      0\n",
      "1  5d272b9dcb            8670          17.0      0\n",
      "2  f6d1b2ba63            4660          38.0      0\n",
      "3  180c632ed8            4660           NaN      0\n",
      "4  4eb37a6705            4660          20.0      0\n",
      "  customer_id customer_region  customer_age  DOW_6\n",
      "0  1b8f824d5e            2360          18.0      1\n",
      "1  5d272b9dcb            8670          17.0      1\n",
      "2  f6d1b2ba63            4660          38.0      1\n",
      "3  180c632ed8            4660           NaN      1\n",
      "4  4eb37a6705            4660          20.0      1\n"
     ]
    }
   ],
   "source": [
    "fixed_columns = ['customer_id', 'customer_region', 'customer_age']\n",
    "\n",
    "for i in range(7):  #DOW_0 a DOW_6\n",
    "    selected_columns = fixed_columns + [f'DOW_{i}']\n",
    "    cluster_df = df[selected_columns]\n",
    "    print(cluster_df.head())\n",
    "\n",
    "selected_columns = fixed_columns + [f'DOW_{i}']\n",
    "\n",
    "cluster_df = df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pedidos totais por dia da semana:\n",
      "DOW_0    17727\n",
      "DOW_1    18096\n",
      "DOW_2    18846\n",
      "DOW_3    19753\n",
      "DOW_4    21612\n",
      "DOW_5    20822\n",
      "DOW_6    22457\n",
      "dtype: int64\n",
      "Distribuição por regiões:\n",
      "customer_region\n",
      "8670    9761\n",
      "4660    9550\n",
      "2360    8829\n",
      "2440    1483\n",
      "4140     857\n",
      "8370     495\n",
      "2490     445\n",
      "-        442\n",
      "8550      26\n",
      "Name: count, dtype: int64\n",
      "Idade mediana: 26.0\n",
      "Distribuição de idades:\n",
      "(14.934000000000001, 28.0]    20303\n",
      "(28.0, 41.0]                   9344\n",
      "(41.0, 54.0]                   1327\n",
      "(54.0, 67.0]                    150\n",
      "(67.0, 80.0]                     37\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Agregar o total de pedidos por dia da semana\n",
    "day_totals = df[['DOW_' + str(i) for i in range(7)]].sum()\n",
    "print(\"Pedidos totais por dia da semana:\")\n",
    "print(day_totals)\n",
    "\n",
    "# Analisar a distribuição de regiões\n",
    "region_counts = df['customer_region'].value_counts()\n",
    "print(\"Distribuição por regiões:\")\n",
    "print(region_counts)\n",
    "\n",
    "# Identificar a idade média e a faixa etária predominante\n",
    "median_age = df['customer_age'].median()\n",
    "age_distribution = df['customer_age'].value_counts(bins=5, sort=False)\n",
    "print(f\"Idade mediana: {median_age}\")\n",
    "print(\"Distribuição de idades:\")\n",
    "print(age_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pedidos no fim de semana: 28.84% do total\n",
      "Top 5 regiões mais ativas:\n",
      "customer_region\n",
      "8670    9761\n",
      "4660    9550\n",
      "2360    8829\n",
      "2440    1483\n",
      "4140     857\n",
      "Name: count, dtype: int64\n",
      "Idades mais frequentes:\n",
      "customer_age\n",
      "23.0    2361\n",
      "22.0    2318\n",
      "24.0    2304\n",
      "25.0    2262\n",
      "26.0    2059\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "weekend_orders = day_totals.loc['DOW_0'] + day_totals.loc['DOW_6']\n",
    "total_orders = day_totals.sum()\n",
    "weekend_percentage = (weekend_orders / total_orders) * 100\n",
    "print(f\"Pedidos no fim de semana: {weekend_percentage:.2f}% do total\")\n",
    "\n",
    "active_regions = region_counts.head(5)\n",
    "print(\"Top 5 regiões mais ativas:\")\n",
    "print(active_regions)\n",
    "\n",
    "most_frequent_ages = df['customer_age'].value_counts().head(5)\n",
    "print(\"Idades mais frequentes:\")\n",
    "print(most_frequent_ages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "customer_id          0\n",
      "customer_region      0\n",
      "customer_age       727\n",
      "DOW_6                0\n",
      "dtype: int64\n",
      "Filling missing values in 'customer_region' with 'Unknown'\n",
      "Missing values after handling:\n",
      "customer_id          0\n",
      "customer_region      0\n",
      "customer_age       727\n",
      "DOW_6                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/1qhsx6xs4ts98l6wng3p3dy00000gn/T/ipykernel_10546/1804974783.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cluster_df[\"customer_region\"].fillna(\"Unknown\", inplace=True)\n",
      "/var/folders/8v/1qhsx6xs4ts98l6wng3p3dy00000gn/T/ipykernel_10546/1804974783.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_df[\"customer_region\"].fillna(\"Unknown\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Define metric and categorical features\n",
    "metric_features = [\"customer_age\", \"DOW_0\", \"DOW_1\", \"DOW_2\", \"DOW_3\", \"DOW_4\", \"DOW_5\", \"DOW_6\"]\n",
    "categorical_features = [\"customer_region\"]\n",
    "\n",
    "# Check for missing values in the DataFrame (cluster_df is the relevant subset)\n",
    "missing_values = cluster_df.isna().sum()\n",
    "\n",
    "# Display missing values by column\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Handle missing values if necessary\n",
    "# Example: Fill missing values in the categorical column\n",
    "if \"customer_region\" in categorical_features:\n",
    "    print(\"Filling missing values in 'customer_region' with 'Unknown'\")\n",
    "    cluster_df[\"customer_region\"].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Check for missing values again after handling\n",
    "print(\"Missing values after handling:\")\n",
    "print(cluster_df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled missing values in 'customer_age' with median: 26.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/1qhsx6xs4ts98l6wng3p3dy00000gn/T/ipykernel_10546/895400887.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cluster_df['customer_age'].fillna(median_age, inplace=True)\n",
      "/var/folders/8v/1qhsx6xs4ts98l6wng3p3dy00000gn/T/ipykernel_10546/895400887.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_df['customer_age'].fillna(median_age, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the median age\n",
    "median_age = cluster_df['customer_age'].median()\n",
    "\n",
    "# Fill missing values with the median\n",
    "cluster_df['customer_age'].fillna(median_age, inplace=True)\n",
    "\n",
    "print(f\"Filled missing values in 'customer_age' with median: {median_age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customer_id customer_region  customer_age  DOW_0  DOW_1  DOW_2  DOW_3  \\\n",
      "0  1b8f824d5e            2360      0.046154      1      0      0      0   \n",
      "1  5d272b9dcb            8670      0.030769      1      0      0      0   \n",
      "2  f6d1b2ba63            4660      0.353846      1      0      0      0   \n",
      "3  180c632ed8            4660           NaN      0      1      0      0   \n",
      "4  4eb37a6705            4660      0.076923      0      1      0      0   \n",
      "\n",
      "   DOW_4  DOW_5  DOW_6  \n",
      "0      0      0      1  \n",
      "1      0      0      1  \n",
      "2      0      0      1  \n",
      "3      0      0      1  \n",
      "4      0      0      1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/1qhsx6xs4ts98l6wng3p3dy00000gn/T/ipykernel_10546/3828700892.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_df[\"customer_age\"] = scaler.fit_transform(cluster_df[[\"customer_age\"]])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Create `cluster_df` with all required columns from `df`\n",
    "cluster_df = df[[\"customer_id\", \"customer_region\", \"customer_age\"] + [f\"DOW_{i}\" for i in range(7)]]\n",
    "\n",
    "# Step 2: Scale `customer_age` using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "cluster_df[\"customer_age\"] = scaler.fit_transform(cluster_df[[\"customer_age\"]])\n",
    "\n",
    "# Step 3: Print the resulting DataFrame\n",
    "print(cluster_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#com base nas coisas que ela fez nas aulas que eu não percebo nada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ss(df, feats):\n",
    "    df_ = df[feats]\n",
    "    ss = np.sum(df_.var() * (df_.count() - 1))\n",
    "    return ss \n",
    "\n",
    "def get_ssb(df, feats, label_col):\n",
    "    ssb_i = 0\n",
    "    for i in np.unique(df[label_col]):\n",
    "        df_ = df[feats]\n",
    "        X_ = df_.values\n",
    "        X_k = df_.loc[df[label_col] == i, feats].values\n",
    "        ssb_i += (X_k.shape[0] * np.square(X_k.mean(axis=0) - X_.mean(axis=0)))\n",
    "    ssb = np.sum(ssb_i)\n",
    "    return ssb\n",
    "\n",
    "def get_ssw(df, feats, label_col):\n",
    "    feats_label = feats + [label_col]\n",
    "    df_k = df[feats_label].groupby(by=label_col).apply(lambda col: get_ss(col, feats))\n",
    "    return df_k.sum()\n",
    "\n",
    "def get_rsq(df, feats, label_col):\n",
    "    df_sst_ = get_ss(df, feats)                 # total sum of squares\n",
    "    df_ssw_ = get_ssw(df, feats, label_col)     # within-cluster sum of squares\n",
    "    df_ssb_ = df_sst_ - df_ssw_                 # between-cluster sum of squares\n",
    "    return df_ssb_ / df_sst_  # R-squared formula\n",
    "\n",
    "def get_r2_hc(df, link_method, max_nclus, min_nclus=1, dist=\"euclidean\"):\n",
    "    r2 = []  # store the R2 metrics for each cluster solution\n",
    "    feats = df.columns.tolist()  # get column names\n",
    "    for i in range(min_nclus, max_nclus + 1):  # iterate over number of clusters\n",
    "        cluster = AgglomerativeClustering(linkage=link_method, metric=dist, n_clusters=i)\n",
    "        hclabels = cluster.fit_predict(df)  # fit clustering\n",
    "        df_concat = pd.concat([df, pd.Series(hclabels, name=\"labels\", index=df.index)], axis=1)\n",
    "        r2.append(get_rsq(df_concat, feats, \"labels\"))  # compute R2\n",
    "    return np.array(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_age    727\n",
      "DOW_0             0\n",
      "DOW_1             0\n",
      "DOW_2             0\n",
      "DOW_3             0\n",
      "DOW_4             0\n",
      "DOW_5             0\n",
      "DOW_6             0\n",
      "dtype: int64\n",
      "  customer_id customer_region  customer_age  DOW_0  DOW_1  DOW_2  DOW_3  \\\n",
      "0  1b8f824d5e            2360      0.046154      1      0      0      0   \n",
      "1  5d272b9dcb            8670      0.030769      1      0      0      0   \n",
      "2  f6d1b2ba63            4660      0.353846      1      0      0      0   \n",
      "3  180c632ed8            4660           NaN      0      1      0      0   \n",
      "4  4eb37a6705            4660      0.076923      0      1      0      0   \n",
      "\n",
      "   DOW_4  DOW_5  DOW_6  \n",
      "0      0      0      1  \n",
      "1      0      0      1  \n",
      "2      0      0      1  \n",
      "3      0      0      1  \n",
      "4      0      0      1  \n"
     ]
    }
   ],
   "source": [
    "print(cluster_df[metric_features].isna().sum())\n",
    "print(cluster_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
